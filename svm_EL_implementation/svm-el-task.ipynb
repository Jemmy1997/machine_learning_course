{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* # Loading all shared libs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  #  loading data and select 20K out of 60k record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\n",
    "df_train = df_train.iloc[:20000]\n",
    "train_features = df_train[df_train.columns[1:]]\n",
    "train_classes = df_train[df_train.columns[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #  loading test and use all of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../input/mnist-in-csv/mnist_test.csv')\n",
    "test_features = df_test[df_test.columns[1:]]\n",
    "test_classes = df_test[df_test.columns[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* > # using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "classes_pred_gnb = gnb.fit(train_features, train_classes).predict(test_features)\n",
    "print(\"Accuracy:\",accuracy_score(test_classes, classes_pred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* > # using Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=None)\n",
    "tree_clf.fit(train_features, train_classes)\n",
    "classes_pred_tree = tree_clf.predict(test_features)\n",
    "print(\"Accuracy:\",accuracy_score(test_classes, classes_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* > # using SVM noting that we are going to use one Vs. All tecgnique as traditional SVM only uses 2 classes to predict and our dataset contain 10 classes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "svm_clf = OneVsRestClassifier(SVC(probability=True)).fit(train_features, train_classes)\n",
    "classes_pred_svm = svm_clf.predict(test_features)\n",
    "print(\"Accuracy:\",accuracy_score(test_classes, classes_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we are going to use the 3 previous classifiers as an input of voting classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * # using Voting classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "bayes = GaussianNB()\n",
    "dtree = DecisionTreeClassifier(max_depth=None)\n",
    "svm = OneVsRestClassifier(SVC(probability=True))\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('svm', svm), ('tree', dtree), ('gnb', bayes)],voting='hard',flatten_transform=True)\n",
    "voting_clf.fit(train_features, train_classes)\n",
    "classes_pred_voting = voting_clf.predict(test_features)\n",
    "print(\"Accuracy:\",accuracy_score(test_classes, classes_pred_voting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will go for bagging and pasting with the fourth one as it's the best accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "voting_clf_bag = VotingClassifier(estimators=[('svm', SVC()), ('tree', dtree), ('gnb', bayes)],voting='hard',flatten_transform=True)\n",
    "bagging_clf = BaggingClassifier(voting_clf_bag)\n",
    "bagging_clf.fit(train_features,train_classes)\n",
    "classes_pred_bagging = bagging_clf.predict(test_features)\n",
    "print(\"Accuracy:\",accuracy_score(test_classes, classes_pred_bagging))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For Pasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9164\n"
     ]
    }
   ],
   "source": [
    "pasting_clf = BaggingClassifier(voting_clf_bag,bootstrap=False)\n",
    "pasting_clf.fit(train_features,train_classes)\n",
    "classes_pred_pasting = pasting_clf.predict(test_features)\n",
    "print(\"Accuracy:\",accuracy_score(test_classes, classes_pred_pasting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These were the results of the required tasks and i passed the deadline due to performance issue on the local machine so i moved into kaggle to use their CPU to accelerate the computations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **References**\n",
    "* [The link of Used dataset](https://www.kaggle.com/oddrationale/mnist-in-csv)\n",
    "* [oneVsAll](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html)\n",
    "* [VotingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)\n",
    "* [Bagging&Pasting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n",
    "* [Ensemble learning Video](https://www.youtube.com/watch?v=KIOeZ5cFZ50&t=3s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
